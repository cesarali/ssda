{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b56b3f8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f7475c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "08f0a7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from abc import ABC\n",
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data import TensorDataset,DataLoader,random_split\n",
    "from torchvision import transforms\n",
    "\n",
    "from typing import Optional, Union, Tuple\n",
    "\n",
    "class BasicDataSet(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "    \n",
    "class DictDataSet(Dataset):\n",
    "    \"\"\"\n",
    "    # Define your data dictionary\n",
    "    data_dict = {'input': torch.randn(2, 10), 'target': torch.randn(2, 5)}\n",
    "\n",
    "    # Create your dataset\n",
    "    my_dataset = DictDataSet(data_dict)\n",
    "\n",
    "    # Create a DataLoader from your dataset\n",
    "    batch_size = 2\n",
    "    dataloader = DataLoader(my_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \"\"\"\n",
    "    def __init__(self, data_dict,transforms=None,key_of_transforms=None):\n",
    "        self.data_dict = data_dict\n",
    "        self.keys = list(data_dict.keys())\n",
    "        if transforms is not None:\n",
    "            self.transforms = transforms\n",
    "            self.key_of_transforms = key_of_transforms\n",
    "        print(self.keys)\n",
    "        print(self.key_of_transforms)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data_dict[self.keys[0]])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_dict = {}\n",
    "        for key in self.keys:\n",
    "            if key == self.key_of_transforms:\n",
    "                batch_dict[key] = self.transforms(self.data_dict[key][idx]).squeeze()\n",
    "            else:\n",
    "                batch_dict[key] = self.data_dict[key][idx]\n",
    "        return batch_dict\n",
    "\n",
    "    \n",
    "with open(\"./data/simulations_metadata.cp\",\"rb\") as file:\n",
    "    simulations_metadata = pickle.load(file)\n",
    "    \n",
    "with open(\"./data/client_metadata.cp\",\"rb\") as file:\n",
    "    client_metadata = pickle.load(file)\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "class BaseDataLoader(ABC):\n",
    "\n",
    "    name_=\"base_data_loader\"\n",
    "\n",
    "    def __init__(self,X:Union[torch.Tensor,dict]=None,type=\"client\",batch_size:int = 32,training_proportion:float = 0.9,device:torch.device=torch.device(\"cpu\"),rank:int=0,**kwargs):\n",
    "        super(BaseDataLoader,self).__init__()\n",
    "        self.training_proportion = training_proportion\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        if type == \"client\":\n",
    "            self.transforms = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[client_metadata[\"rescaling\"][0]], std=[client_metadata[\"rescaling\"][0]]),\n",
    "                transforms.Resize((11, 24))\n",
    "            ])\n",
    "            self.key_of_transforms = \"y_diff\"\n",
    "        elif type== \"simulations\":\n",
    "            self.transforms = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[simulations_metadata[\"rescaling\"][0]], std=[simulations_metadata[\"rescaling\"][0]]),\n",
    "                transforms.Resize((11, 24))\n",
    "            ])\n",
    "            self.key_of_transforms = \"nds\"\n",
    "            \n",
    "        self.define_dataset_and_dataloaders(X)\n",
    "        \n",
    "    def define_dataset_and_dataloaders(self,X,training_proportion=None,batch_size=None):\n",
    "        if training_proportion is not None:\n",
    "            self.training_proportion=training_proportion\n",
    "        if batch_size is not None:\n",
    "            self.batch_size = batch_size\n",
    "\n",
    "        if isinstance(X,torch.Tensor):\n",
    "            dataset = TensorDataset(X)\n",
    "        elif isinstance(X,dict):\n",
    "            dataset = DictDataSet(X,self.transforms,self.key_of_transforms)\n",
    "\n",
    "        self.total_data_size = len(dataset)\n",
    "        self.training_data_size = int(self.training_proportion * self.total_data_size)\n",
    "        self.test_data_size = self.total_data_size - self.training_data_size\n",
    "\n",
    "        training_dataset, test_dataset = random_split(dataset, [self.training_data_size, self.test_data_size])\n",
    "        self._train_iter = DataLoader(training_dataset, batch_size=self.batch_size)\n",
    "        self._test_iter = DataLoader(test_dataset, batch_size=self.batch_size)\n",
    "\n",
    "    def train(self):\n",
    "        return self._train_iter\n",
    "\n",
    "    def test(self):\n",
    "        return self._test_iter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "7147a7d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "60ab85ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "with open(\"./data/client_.cp\",\"rb\") as file:\n",
    "    clients_data = pickle.load(file)\n",
    "    #clients_data[\"y_diff\"] = torch.Tensor(clients_data[\"y_diff\"])\n",
    "with open(\"./data/simulations_.cp\",\"rb\") as file:\n",
    "    simulations_data = pickle.load(file)\n",
    "    #simulations_data[\"nds\"] = torch.Tensor(simulations_data[\"nds\"])\n",
    "\n",
    "client_data_loader = BaseDataLoader(clients_data,type=\"client\")\n",
    "simulations_data_loader = BaseDataLoader(simulations_data,type=\"simulations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "59823fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['names', 'y_diff', 'PoDm_dist']\n",
      "y_diff\n",
      "['nds', 'PoDmD', 'name']\n",
      "nds\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "28b8e804",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_databatch = next(client_data_loader.train().__iter__())\n",
    "simulations_databatch = next(simulations_data_loader.train().__iter__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "f9321f43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 11, 24])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "databatch['y_diff'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "d3c09b4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "bbc2b506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 11, 24])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "databatch[\"nds\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "014f321b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 88, 24])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ".shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e1980fd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08676f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms.Compose([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdf6486",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
